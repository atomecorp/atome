<!DOCTYPE html>
<html lang="fr">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Découpage Audio</title>
	<style>
		body {
			font-family: Arial, sans-serif;
			max-width: 1000px;
			margin: 0 auto;
			padding: 20px;
			background-color: #f5f5f5;
		}
		h1 {
			color: #333;
			text-align: center;
			margin-bottom: 30px;
		}
		.container {
			background-color: white;
			border-radius: 10px;
			padding: 20px;
			box-shadow: 0 2px 10px rgba(0,0,0,0.1);
		}
		.form-group {
			margin-bottom: 20px;
		}
		label {
			display: block;
			margin-bottom: 8px;
			font-weight: bold;
		}
		input, select {
			width: 100%;
			padding: 10px;
			border: 1px solid #ddd;
			border-radius: 4px;
			box-sizing: border-box;
		}
		button {
			background-color: #4285f4;
			color: white;
			border: none;
			padding: 12px 20px;
			border-radius: 4px;
			cursor: pointer;
			font-size: 16px;
			margin-top: 10px;
		}
		button:hover {
			background-color: #3367d6;
		}
		button:disabled {
			background-color: #cccccc;
			cursor: not-allowed;
		}
		.waveform-container {
			margin-top: 20px;
			position: relative;
			background-color: #f0f0f0;
			border-radius: 5px;
			overflow: hidden;
			height: 200px;
		}
		#waveform {
			width: 100%;
			height: 100%;
		}
		.progress {
			margin-top: 20px;
		}
		.progress-bar {
			height: 20px;
			background-color: #e0e0e0;
			border-radius: 10px;
			margin-bottom: 10px;
			overflow: hidden;
		}
		.progress-bar-fill {
			height: 100%;
			background-color: #4285f4;
			width: 0%;
			transition: width 0.3s;
		}
		.segment-marker {
			position: absolute;
			width: 2px;
			height: 100%;
			background-color: red;
			z-index: 5;
		}
		.file-list {
			margin-top: 30px;
			display: none;
		}
		.file-item {
			display: flex;
			justify-content: space-between;
			align-items: center;
			padding: 12px;
			background-color: #f9f9f9;
			border-radius: 4px;
			margin-bottom: 10px;
		}
		.file-item:hover {
			background-color: #f0f0f0;
		}
		.file-name {
			flex-grow: 1;
		}
		.file-actions {
			display: flex;
			gap: 10px;
		}
		.download-btn {
			background-color: #34a853;
			color: white;
			border: none;
			padding: 6px 12px;
			border-radius: 4px;
			cursor: pointer;
		}
		.download-btn:hover {
			background-color: #2d8e47;
		}
		.options-container {
			display: flex;
			gap: 20px;
			margin-bottom: 20px;
		}
		.option-col {
			flex: 1;
		}
		.section-title {
			margin-top: 30px;
			color: #444;
			border-bottom: 1px solid #ddd;
			padding-bottom: 10px;
		}
	</style>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/wavesurfer.js/6.6.3/wavesurfer.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
</head>
<body>
			<h1>Découpage Audio</h1>

	<div class="container">
		<p style="margin-bottom: 20px; color: #555;">Cette application découpe votre fichier audio en segments qui commencent toujours par un son (jamais par un silence). Les points de découpage sont placés aux transitions silence→son.</p>
		<h2 class="section-title">Importer un fichier audio</h2>
		<div class="form-group">
			<label for="audio-file">Sélectionner un fichier audio:</label>
			<input type="file" id="audio-file" accept="audio/*">
		</div>

		<div class="waveform-container">
			<div id="waveform"></div>
			<!-- Les marqueurs de segment seront ajoutés ici dynamiquement -->
		</div>
		<button id="listen-btn" disabled>Écouter l'audio</button>

		<h2 class="section-title">Options de découpage</h2>
		<div class="options-container">
			<div class="option-col">
				<div class="form-group">
					<label for="slice-method">Méthode de découpage:</label>
					<select id="slice-method">
						<option value="silence">Découper aux transitions silence→son</option>
						<option value="equal">En segments égaux</option>
					</select>
				</div>

				<div class="form-group" id="threshold-group">
					<label for="threshold">Seuil de silence (0-1):</label>
					<input type="number" id="threshold" min="0.001" max="0.5" step="0.001" value="0.01">
					<small style="display: block; margin-top: 5px; color: #666;">Valeurs recommandées: 0.005-0.02. Plus la valeur est basse, plus la détection sera sensible aux vrais silences.</small>
				</div>

				<div class="form-group" id="segment-count-group" style="display: none;">
					<label for="segment-count">Nombre de segments:</label>
					<input type="number" id="segment-count" min="2" max="100" value="10">
				</div>
			</div>

			<div class="option-col">
				<div class="form-group">
					<label for="min-silence">Durée minimum de silence (secondes):</label>
					<input type="number" id="min-silence" min="0.05" max="5" step="0.05" value="0.1">
					<small style="display: block; margin-top: 5px; color: #666;">Réduisez cette valeur (0.05-0.1s) pour détecter les silences très courts.</small>
				</div>

				<div class="form-group">
					<label for="min-segment">Durée minimum d'un segment (secondes):</label>
					<input type="number" id="min-segment" min="0.1" max="10" step="0.1" value="0.3">
				</div>
			</div>
		</div>

		<button id="analyze-btn" disabled>Re-analyser l'audio</button>
		<button id="slice-btn" disabled>Découper l'audio</button>

		<div class="progress" style="display: none;">
			<p id="progress-text">Traitement en cours...</p>
			<div class="progress-bar">
				<div class="progress-bar-fill"></div>
			</div>
		</div>

		<div class="file-list" id="file-list">
			<h2 class="section-title">Segments générés</h2>
			<div id="segment-list"></div>
			<button id="download-all-btn" style="background-color: #ea4335; color: white; border: none; padding: 12px 20px; border-radius: 4px; cursor: pointer; font-size: 16px; margin-top: 20px; display: block; width: 100%; text-align: center;">Télécharger tous les segments (ZIP)</button>
			<p style="margin-top: 10px; font-size: 14px; color: #666; font-style: italic;">Note: La création du fichier ZIP peut prendre un moment pour les fichiers volumineux.</p>
		</div>
	</div>

	<script>
	document.addEventListener('DOMContentLoaded', function() {
		// Éléments DOM
		const audioFileInput = document.getElementById('audio-file');
		const sliceMethodSelect = document.getElementById('slice-method');
		const thresholdInput = document.getElementById('threshold');
		const thresholdGroup = document.getElementById('threshold-group');
		const segmentCountInput = document.getElementById('segment-count');
		const segmentCountGroup = document.getElementById('segment-count-group');
		const minSilenceInput = document.getElementById('min-silence');
		const minSegmentInput = document.getElementById('min-segment');
		const analyzeBtn = document.getElementById('analyze-btn');
		const sliceBtn = document.getElementById('slice-btn');
		const progressBar = document.querySelector('.progress');
		const progressBarFill = document.querySelector('.progress-bar-fill');
		const progressText = document.getElementById('progress-text');
		const fileList = document.getElementById('file-list');
		const segmentList = document.getElementById('segment-list');
		const waveformContainer = document.querySelector('.waveform-container');
		const downloadAllBtn = document.getElementById('download-all-btn');
		const listenBtn = document.getElementById('listen-btn');

		// Variables globales
		let audioContext;
		let audioBuffer;
		let audioFile;
		let fileName;
		let fileExtension;
		let wavesurfer;
		let segments = [];
		let generatedFiles = [];

		// Initialiser WaveSurfer
		function initWaveSurfer() {
			if (wavesurfer) {
				wavesurfer.destroy();
			}

			wavesurfer = WaveSurfer.create({
				container: '#waveform',
				waveColor: '#4285f4',
				progressColor: '#3367d6',
				cursorColor: '#333',
				height: 200,
				responsive: true,
				normalize: true,
				barWidth: 2,
				barGap: 1
			});

			wavesurfer.on('ready', function() {
				analyzeBtn.disabled = false;
				listenBtn.disabled = false;
				progressBar.style.display = 'none';
			});

			wavesurfer.on('error', function(err) {
				console.error('WaveSurfer error:', err);
				alert('Erreur lors du chargement de l\'audio: ' + err.message);
				progressBar.style.display = 'none';
			});
		}

		// Initialiser l'AudioContext
		function initAudioContext() {
			if (!audioContext) {
				audioContext = new (window.AudioContext || window.webkitAudioContext)();
			}
		}

		// Chargement du fichier audio
		audioFileInput.addEventListener('change', function(e) {
			if (this.files.length === 0) return;

			audioFile = this.files[0];
			const fullFileName = audioFile.name;
			const lastDotIndex = fullFileName.lastIndexOf('.');

			if (lastDotIndex !== -1) {
				fileName = fullFileName.substring(0, lastDotIndex);
				fileExtension = fullFileName.substring(lastDotIndex);
			} else {
				fileName = fullFileName;
				fileExtension = '';
			}

			initWaveSurfer();

			// Afficher la progression
			progressBar.style.display = 'block';
			progressText.textContent = 'Chargement de l\'audio...';
			progressBarFill.style.width = '0%';

			// Charger dans WaveSurfer
			wavesurfer.loadBlob(audioFile);

			// Charger dans AudioContext pour l'analyse
			initAudioContext();
			const reader = new FileReader();
			reader.onload = function(e) {
				const arrayBuffer = e.target.result;
				audioContext.decodeAudioData(arrayBuffer)
					.then(buffer => {
						audioBuffer = buffer;
						progressBarFill.style.width = '100%';
						analyseSample();
					})
					.catch(err => {
						console.error('Erreur lors du décodage audio:', err);
						alert('Erreur lors du décodage audio: ' + err.message);
					});
			};
			reader.onerror = function(err) {
				console.error('Erreur lors de la lecture du fichier:', err);
				alert('Erreur lors de la lecture du fichier');
			};
		
		
			reader.readAsArrayBuffer(audioFile);

			// Réinitialiser les segments
			segments = [];
			generatedFiles = [];
			clearSegmentMarkers();
			fileList.style.display = 'none';
			segmentList.innerHTML = '';
			sliceBtn.disabled = true;
			////// here /////
			// analyseSample()
		});

		// Changement de méthode de découpage
		sliceMethodSelect.addEventListener('change', function() {
			if (this.value === 'silence') {
				thresholdGroup.style.display = 'block';
				segmentCountGroup.style.display = 'none';
			} else {
				thresholdGroup.style.display = 'none';
				segmentCountGroup.style.display = 'block';
			}
		});

		// Analyser l'audio
		function analyseSample() {
			if (!audioBuffer) {
				alert('Veuillez d\'abord charger un fichier audio.');
				return;
			}
		
			progressBar.style.display = 'block';
			progressText.textContent = 'Analyse en cours...';
			progressBarFill.style.width = '0%';
		
			// Simuler un délai pour l'analyse (esthétique)
			setTimeout(() => {
				try {
					if (sliceMethodSelect.value === 'silence') {
						findSilencePoints();
					} else {
						createEqualSegments();
					}
		
					displaySegmentMarkers();
					sliceBtn.disabled = false;
		
					progressBarFill.style.width = '100%';
					progressText.textContent = 'Analyse terminée. ' + segments.length + ' segments détectés.';
					sliceAudio();
				} catch (err) {
					console.error('Erreur lors de l\'analyse:', err);
					alert('Erreur lors de l\'analyse: ' + err.message);
					progressBar.style.display = 'none';
				}
			}, 500);
		}
		analyzeBtn.addEventListener('click', function(){
			analyseSample();
		});

		// Trouver les points de silence et construire des segments commençant par du son
		function findSilencePoints() {
			const threshold = parseFloat(thresholdInput.value);
			const minSilence = parseFloat(minSilenceInput.value);
			const minSegment = parseFloat(minSegmentInput.value);

			// Récupérer les données audio
			const channelData = audioBuffer.getChannelData(0); // Utiliser le premier canal pour l'analyse
			const sampleRate = audioBuffer.sampleRate;
			const bufferLength = channelData.length;

			// Calculer la taille des fenêtres d'analyse
			const windowSize = Math.floor(sampleRate * 0.01); // Fenêtre de 10ms
			const stepSize = Math.floor(windowSize / 4); // Chevauchement de 75%

			// Initialiser les tableaux pour stocker les résultats
			const rmsValues = [];
			const isSilence = [];

			// Calculer les valeurs RMS pour chaque fenêtre
			for (let i = 0; i < bufferLength; i += stepSize) {
				if (i + windowSize > bufferLength) break;

				let sum = 0;
				for (let j = 0; j < windowSize; j++) {
					sum += channelData[i + j] * channelData[i + j];
				}
				const rms = Math.sqrt(sum / windowSize);
				rmsValues.push(rms);

				// Déterminer si c'est du silence
				isSilence.push(rms < threshold);
			}

			// Convertir en secondes
			const frameDuration = stepSize / sampleRate;

			// Trouver les transitions silence → son (pour commencer les segments au début du son)
			const soundStartPoints = [];

			// Ajouter le début du fichier si ce n'est pas un silence
			if (!isSilence[0]) {
				soundStartPoints.push(0);
			}

			// Trouver toutes les transitions silence → son
			for (let i = 1; i < isSilence.length; i++) {
				if (isSilence[i-1] && !isSilence[i]) {
					// Transition du silence vers le son - ajuster légèrement pour éviter le blanc
					const adjustedStartTime = Math.max(0, (i * frameDuration) - 0.001); // 1ms avant la transition
					soundStartPoints.push(adjustedStartTime);
				}
			}

			console.log('Points de début de son détectés:', soundStartPoints);

			// Si nous n'avons pas trouvé de points de départ, essayer avec un seuil plus bas
			if (soundStartPoints.length <= 1) {
				const adaptiveThreshold = threshold * 0.5; // 50% du seuil original
				console.log('Essai avec un seuil adaptatif de', adaptiveThreshold);

				// Recalculer avec le nouveau seuil
				for (let i = 0; i < rmsValues.length; i++) {
					isSilence[i] = rmsValues[i] < adaptiveThreshold;
				}

				// Vider et reconstruire les points de départ
				soundStartPoints.length = 0;

				// Ajouter le début du fichier si ce n'est pas un silence
				if (!isSilence[0]) {
					soundStartPoints.push(0);
				}

				// Trouver toutes les transitions silence → son avec le nouveau seuil
				for (let i = 1; i < isSilence.length; i++) {
					if (isSilence[i-1] && !isSilence[i]) {
						const adjustedStartTime = Math.max(0, (i * frameDuration) - 0.001);
						soundStartPoints.push(adjustedStartTime);
					}
				}

				console.log('Points de début de son avec seuil adaptatif:', soundStartPoints);
			}

			// Si toujours aucun point trouvé, utiliser une approche basée sur les pics audio relatifs
			if (soundStartPoints.length <= 1) {
				console.log('Passage à la détection basée sur les variations d\'amplitude');

				// Calculer la moyenne et l'écart-type des valeurs RMS
				let meanRMS = 0;
				for (const rms of rmsValues) {
					meanRMS += rms;
				}
				meanRMS /= rmsValues.length;

				let stdDevRMS = 0;
				for (const rms of rmsValues) {
					stdDevRMS += (rms - meanRMS) * (rms - meanRMS);
				}
				stdDevRMS = Math.sqrt(stdDevRMS / rmsValues.length);

				// Détecter les pics (valeurs qui dépassent la moyenne + une fraction de l'écart-type)
				const peakThreshold = meanRMS + 0.5 * stdDevRMS;

				// Trouver les débuts des pics significatifs
				let inPeak = false;
				for (let i = 0; i < rmsValues.length; i++) {
					if (!inPeak && rmsValues[i] > peakThreshold) {
						inPeak = true;
						soundStartPoints.push(i * frameDuration);
					} else if (inPeak && rmsValues[i] <= peakThreshold) {
						inPeak = false;
					}
				}

				console.log('Points de pic détectés:', soundStartPoints);
			}

			// S'assurer que nous commençons par le début du fichier si aucun point n'a été trouvé près du début
			if (soundStartPoints.length === 0 || soundStartPoints[0] > minSegment) {
				soundStartPoints.unshift(0);
			}

			// Filtrer les points trop proches les uns des autres
			const filteredStartPoints = [soundStartPoints[0]];
			for (let i = 1; i < soundStartPoints.length; i++) {
				if (soundStartPoints[i] - filteredStartPoints[filteredStartPoints.length - 1] >= minSegment) {
					// Ignorer les points qui sont trop proches de la fin du fichier
					if (audioBuffer.duration - soundStartPoints[i] < minSegment * 1.5) {
						console.log(`Point ignoré car trop proche de la fin: ${soundStartPoints[i]}`);
						continue;
					}

					filteredStartPoints.push(soundStartPoints[i]);
				}
			}

			// Créer les segments basés sur les points de début de son
			segments = [];
			for (let i = 0; i < filteredStartPoints.length; i++) {
				const start = filteredStartPoints[i];
				let end;

				if (i < filteredStartPoints.length - 1) {
					// Pour tous les segments sauf le dernier, la fin est le début du segment suivant
					end = filteredStartPoints[i + 1];
				} else {
					// Pour le dernier segment, la fin est la fin du fichier audio
					end = audioBuffer.duration;
				}

				// Ne pas créer de segments trop courts
				if (end - start >= minSegment) {
					segments.push({
						start: start,
						end: end
					});
				}
			}

			console.log('Segments finaux commençant par du son:', segments);

			// Si aucun segment n'est trouvé, créer un segment couvrant tout le fichier
			if (segments.length === 0) {
				segments.push({
					start: 0,
					end: audioBuffer.duration
				});
			}
		}

		// Créer des segments égaux
		function createEqualSegments() {
			const segmentCount = parseInt(segmentCountInput.value);
			const duration = audioBuffer.duration;
			const segmentDuration = duration / segmentCount;

			segments = [];

			for (let i = 0; i < segmentCount; i++) {
				const start = i * segmentDuration;
				const end = (i + 1) * segmentDuration;
				segments.push({
					start: start,
					end: Math.min(end, duration)
				});
			}

			console.log('Segments égaux:', segments);
		}

		// Afficher les marqueurs de segment sur la forme d'onde
		function displaySegmentMarkers() {
			clearSegmentMarkers();

			const totalWidth = waveformContainer.clientWidth;
			const totalDuration = audioBuffer.duration;

			segments.forEach(segment => {
				// Marqueur pour le début du segment (sauf le premier)
				if (segment.start > 0) {
					const startMarker = document.createElement('div');
					startMarker.className = 'segment-marker';
					startMarker.style.left = (segment.start / totalDuration * 100) + '%';
					waveformContainer.appendChild(startMarker);
				}
			});
		}

		// Effacer tous les marqueurs de segment
		function clearSegmentMarkers() {
			const markers = waveformContainer.querySelectorAll('.segment-marker');
			markers.forEach(marker => marker.remove());
		}

		// Découper l'audio
	async	function sliceAudio(){
			if (segments.length === 0) {
				alert('Veuillez d\'abord analyser l\'audio.');
				return;
			}
			
			progressBar.style.display = 'block';
			progressText.textContent = 'Découpage en cours...';
			progressBarFill.style.width = '0%';
			
			const totalSegments = segments.length;
			generatedFiles = [];
			
			for (let i = 0; i < totalSegments; i++) {
				const segment = segments[i];
			
				// Affiner le début du segment pour supprimer les 2-3ms de silence potentielles
				let refinedStart = segment.start;
				const sampleStart = Math.floor(segment.start * audioBuffer.sampleRate);
				const refinementWindow = Math.floor(0.01 * audioBuffer.sampleRate); // 10ms maximum à vérifier
				const channelData = audioBuffer.getChannelData(0);
			
				// Chercher le vrai début du son en analysant échantillon par échantillon
				for (let j = 0; j < refinementWindow; j++) {
					const samplePos = sampleStart + j;
					if (samplePos >= channelData.length) break;
			
					// Vérifier si l'amplitude dépasse un seuil dynamique basé sur l'amplitude maximale du segment
					const amplitude = Math.abs(channelData[samplePos]);
					if (amplitude > parseFloat(thresholdInput.value) * 0.7) {
						refinedStart = (sampleStart + j) / audioBuffer.sampleRate;
						break;
					}
				}
			
				// Si le raffinement a trop avancé le début, revenir légèrement en arrière
				// pour ne pas tronquer l'attaque du son
				if (refinedStart > segment.start) {
					const msToPreserve = 0.002; // 2ms de pré-attaque à préserver
					refinedStart = Math.max(segment.start, refinedStart - msToPreserve);
				}
			
				const segmentDuration = segment.end - refinedStart;
			
				// Vérifier si le segment a un contenu audio significatif
				let hasSound = false;
				const minThreshold = 0.005; // Seuil minimal pour détecter du son
			
				// Analyser rapidement le segment pour vérifier s'il contient du son
				const startSample = Math.floor(refinedStart * audioBuffer.sampleRate);
				const endSample = Math.floor(segment.end * audioBuffer.sampleRate);
			
				// Vérifier un échantillon sur 100 pour des raisons de performance
				for (let j = startSample; j < endSample; j += 100) {
					if (j < channelData.length && Math.abs(channelData[j]) > minThreshold) {
						hasSound = true;
						break;
					}
				}
			
				// Ignorer les segments vides
				if (!hasSound) {
					console.log(`Segment ${i+1} ignoré car vide`);
					continue;
				}
			
				// Créer un nouveau buffer pour le segment
				const segmentBuffer = audioContext.createBuffer(
					audioBuffer.numberOfChannels,
					Math.floor(segmentDuration * audioBuffer.sampleRate),
					audioBuffer.sampleRate
				);
			
				// Copier les données audio du segment
				for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
					const channelData = audioBuffer.getChannelData(channel);
					const segmentData = segmentBuffer.getChannelData(channel);
			
					const startSample = Math.floor(refinedStart * audioBuffer.sampleRate);
					const endSample = Math.floor(segment.end * audioBuffer.sampleRate);
			
					for (let j = 0; j < segmentData.length; j++) {
						if (startSample + j < channelData.length) {
							segmentData[j] = channelData[startSample + j];
						}
					}
				}
			
				// Appliquer un fondu d'entrée très court pour éviter les clics
				const fadeSamples = Math.floor(0.001 * audioBuffer.sampleRate); // 1ms de fondu
				for (let channel = 0; channel < segmentBuffer.numberOfChannels; channel++) {
					const data = segmentBuffer.getChannelData(channel);
					for (let j = 0; j < fadeSamples; j++) {
						if (j < data.length) {
							data[j] *= (j / fadeSamples);
						}
					}
				}
			
				// Convertir le buffer en blob WAV
				const segmentWav = await audioBufferToWav(segmentBuffer);
				const segmentBlob = new Blob([segmentWav], { type: 'audio/wav' });
			
				// Créer un nom de fichier pour le segment
				const segmentName = `${fileName}_${generatedFiles.length + 1}.wav`;
			
				generatedFiles.push({
					name: segmentName,
					blob: segmentBlob,
					duration: segmentDuration
				});
			
				// Mettre à jour la progression
				progressBarFill.style.width = ((i + 1) / totalSegments * 100) + '%';
			}
			
			progressText.textContent = 'Découpage terminé. ' + generatedFiles.length + ' segments générés.';
			
			// Afficher la liste des fichiers
			displayFileList(generatedFiles);
		}
		
		sliceBtn.addEventListener('click', async function() {
			sliceAudio();
		});

		// Afficher la liste des fichiers générés
		function displayFileList(files) {
			fileList.style.display = 'block';
			segmentList.innerHTML = '';

			files.forEach((file, index) => {
				const itemEl = document.createElement('div');
				itemEl.className = 'file-item';

				const nameEl = document.createElement('div');
				nameEl.className = 'file-name';
				nameEl.textContent = `${file.name} (${file.duration.toFixed(2)}s)`;

				const actionsEl = document.createElement('div');
				actionsEl.className = 'file-actions';

				const downloadBtn = document.createElement('button');
				downloadBtn.className = 'download-btn';
				downloadBtn.textContent = 'Télécharger';
				downloadBtn.addEventListener('click', () => {
					downloadFile(file.blob, file.name);
				});

				const listenBtn = document.createElement('button');
				listenBtn.className = 'download-btn';
				listenBtn.textContent = 'Écouter';
				listenBtn.addEventListener('click', () => {
					const audio = new Audio(URL.createObjectURL(file.blob));
					audio.play();
				});

				actionsEl.appendChild(downloadBtn);
				actionsEl.appendChild(listenBtn);
				itemEl.appendChild(nameEl);
				itemEl.appendChild(actionsEl);
				segmentList.appendChild(itemEl);
			});
		}

		// Télécharger un fichier
		function downloadFile(blob, fileName) {
			const url = URL.createObjectURL(blob);
			const a = document.createElement('a');
			a.style.display = 'none';
			a.href = url;
			a.download = fileName;
			document.body.appendChild(a);
			a.click();
			setTimeout(() => {
				document.body.removeChild(a);
				URL.revokeObjectURL(url);
			}, 100);
		}

		// Convertir un AudioBuffer en WAV
		async function audioBufferToWav(buffer) {
			const numOfChan = buffer.numberOfChannels;
			const length = buffer.length * numOfChan * 2 + 44;
			const result = new Uint8Array(length);
			const view = new DataView(result.buffer);

			// RIFF identifier
			writeString(view, 0, 'RIFF');
			// File length
			view.setUint32(4, length - 8, true);
			// RIFF type
			writeString(view, 8, 'WAVE');
			// Format chunk identifier
			writeString(view, 12, 'fmt ');
			// Format chunk length
			view.setUint32(16, 16, true);
			// Sample format (raw)
			view.setUint16(20, 1, true);
			// Channel count
			view.setUint16(22, numOfChan, true);
			// Sample rate
			view.setUint32(24, buffer.sampleRate, true);
			// Byte rate (sample rate * block align)
			view.setUint32(28, buffer.sampleRate * numOfChan * 2, true);
			// Block align (channel count * bytes per sample)
			view.setUint16(32, numOfChan * 2, true);
			// Bits per sample
			view.setUint16(34, 16, true);
			// Data chunk identifier
			writeString(view, 36, 'data');
			// Data chunk length
			view.setUint32(40, length - 44, true);

			// Write the PCM samples
			const offset = 44;
			const channelData = [];
			let pos = 0;

			// Get the channel data
			for (let i = 0; i < numOfChan; i++) {
				channelData.push(buffer.getChannelData(i));
			}

			// Interleave the channels
			while (pos < buffer.length) {
				for (let i = 0; i < numOfChan; i++) {
					// Clamp the value to the range [-1, 1]
					let sample = Math.max(-1, Math.min(1, channelData[i][pos]));
					// Convert to 16-bit signed integer
					sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
					view.setInt16(offset + (pos * numOfChan + i) * 2, sample, true);
				}
				pos++;
			}

			return result.buffer;
		}

		// Écrire une chaîne dans la vue
		function writeString(view, offset, string) {
			for (let i = 0; i < string.length; i++) {
				view.setUint8(offset + i, string.charCodeAt(i));
			}
		}

		// Télécharger tous les fichiers sous forme de ZIP
		downloadAllBtn.addEventListener('click', async function() {
			if (generatedFiles.length === 0) {
				alert('Aucun segment à télécharger.');
				return;
			}

			progressBar.style.display = 'block';
			progressText.textContent = 'Création du fichier ZIP...';
			progressBarFill.style.width = '0%';

			try {
				const zip = new JSZip();

				// Ajouter chaque fichier au ZIP
				for (let i = 0; i < generatedFiles.length; i++) {
					const file = generatedFiles[i];
					zip.file(file.name, file.blob);

					// Mettre à jour la progression
					progressBarFill.style.width = ((i + 1) / generatedFiles.length * 70) + '%';
				}

				// Générer le ZIP
				progressText.textContent = 'Génération du fichier ZIP...';
				const zipBlob = await zip.generateAsync({
					type: 'blob',
					compression: 'DEFLATE',
					compressionOptions: { level: 6 }
				}, function(metadata) {
					progressBarFill.style.width = (70 + metadata.percent * 0.3) + '%';
				});

				// Télécharger le ZIP
				const zipName = `${fileName}_segments.zip`;
				downloadFile(zipBlob, zipName);

				progressBarFill.style.width = '100%';
				progressText.textContent = 'Téléchargement terminé!';

				// Cacher la barre de progression après 2 secondes
				setTimeout(() => {
					progressBar.style.display = 'none';
				}, 2000);
			} catch (err) {
				console.error('Erreur lors de la création du ZIP:', err);
				alert('Erreur lors de la création du fichier ZIP: ' + err.message);
				progressBar.style.display = 'none';
			}
		});

		// Écouter l'audio complet
		listenBtn.addEventListener('click', function() {
			if (wavesurfer) {
				wavesurfer.play();
			}
		});

		// Initialiser l'application
		initWaveSurfer();
	});
	</script>
</body>
</html>
